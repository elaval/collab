{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "highered_dropout.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elaval/collab/blob/master/highered_dropout.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "GljK6F3F0-r8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Carga de librerías externas"
      ]
    },
    {
      "metadata": {
        "id": "j8CjSIGAbGyy",
        "colab_type": "code",
        "outputId": "effa433c-bd66-4876-dcbf-3e1636d2de85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1669
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install numpy scipy pydash\n",
        "!pip install resampy tensorflow six\n",
        "!pip install tensorflowjs\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python2.7/dist-packages (1.14.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python2.7/dist-packages (1.1.0)\n",
            "Collecting pydash\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/38/f1/bcbf51d5b05229b0e42979c6b29b71bfcc277519a0f2fe695f47ad36b6d6/pydash-4.7.4-py2.py3-none-any.whl (84kB)\n",
            "\u001b[K    100% |████████████████████████████████| 92kB 5.5MB/s \n",
            "\u001b[?25hInstalling collected packages: pydash\n",
            "Successfully installed pydash-4.7.4\n",
            "Requirement already satisfied: resampy in /usr/local/lib/python2.7/dist-packages (0.2.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python2.7/dist-packages (1.12.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (1.11.0)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python2.7/dist-packages (from resampy) (1.14.6)\n",
            "Requirement already satisfied: scipy>=0.13 in /usr/local/lib/python2.7/dist-packages (from resampy) (1.1.0)\n",
            "Requirement already satisfied: numba>=0.32 in /usr/local/lib/python2.7/dist-packages (from resampy) (0.40.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (2.0.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (1.0.6)\n",
            "Requirement already satisfied: enum34>=1.1.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (1.1.6)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (3.6.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (1.0.5)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (0.2.1.post0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python2.7/dist-packages (from tensorflow) (0.32.3)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (0.6.1)\n",
            "Requirement already satisfied: backports.weakref>=1.0rc1 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (1.0.post1)\n",
            "Requirement already satisfied: tensorboard<1.13.0,>=1.12.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (1.12.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied: funcsigs in /usr/local/lib/python2.7/dist-packages (from numba>=0.32->resampy) (1.0.2)\n",
            "Requirement already satisfied: llvmlite>=0.25.0dev0 in /usr/local/lib/python2.7/dist-packages (from numba>=0.32->resampy) (0.27.0)\n",
            "Requirement already satisfied: singledispatch in /usr/local/lib/python2.7/dist-packages (from numba>=0.32->resampy) (3.4.0.3)\n",
            "Requirement already satisfied: futures>=2.2.0 in /usr/local/lib/python2.7/dist-packages (from grpcio>=1.8.6->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0->tensorflow) (5.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python2.7/dist-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python2.7/dist-packages (from protobuf>=3.6.1->tensorflow) (40.6.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python2.7/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python2.7/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow) (3.0.1)\n",
            "Collecting tensorflowjs\n",
            "  Downloading https://files.pythonhosted.org/packages/d3/51/df68ccf265cd96d3aa6fcefdfa58262ec67b0efc16911d3f3ea2f4398bd8/tensorflowjs-0.6.7-py2-none-any.whl\n",
            "Collecting keras==2.2.2 (from tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/7d/b1dedde8af99bd82f20ed7e9697aac0597de3049b1f786aa2aac3b9bd4da/Keras-2.2.2-py2.py3-none-any.whl (299kB)\n",
            "\u001b[K    100% |████████████████████████████████| 307kB 24.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py==2.8.0 in /usr/local/lib/python2.7/dist-packages (from tensorflowjs) (2.8.0)\n",
            "Requirement already satisfied: tensorflow==1.12.0 in /usr/local/lib/python2.7/dist-packages (from tensorflowjs) (1.12.0)\n",
            "Collecting numpy==1.15.1 (from tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/16/1134977cc35d2f72dbe80efa75a8e989ac21289f8e7e2c9005444cd17cd5/numpy-1.15.1-cp27-cp27mu-manylinux1_x86_64.whl (13.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 13.8MB 1.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six==1.11.0 in /usr/local/lib/python2.7/dist-packages (from tensorflowjs) (1.11.0)\n",
            "Collecting tensorflow-hub==0.1.1 (from tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5f/22/64f246ef80e64b1a13b2f463cefa44f397a51c49a303294f5f3d04ac39ac/tensorflow_hub-0.1.1-py2.py3-none-any.whl (52kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 12.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.14 in /usr/local/lib/python2.7/dist-packages (from keras==2.2.2->tensorflowjs) (1.1.0)\n",
            "Collecting keras-preprocessing==1.0.2 (from keras==2.2.2->tensorflowjs)\n",
            "  Downloading https://files.pythonhosted.org/packages/71/26/1e778ebd737032749824d5cba7dbd3b0cf9234b87ab5ec79f5f0403ca7e9/Keras_Preprocessing-1.0.2-py2.py3-none-any.whl\n",
            "Collecting keras-applications==1.0.4 (from keras==2.2.2->tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/90/8f327deaa37a71caddb59b7b4aaa9d4b3e90c0e76f8c2d1572005278ddc5/Keras_Applications-1.0.4-py2.py3-none-any.whl (43kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 22.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python2.7/dist-packages (from keras==2.2.2->tensorflowjs) (3.13)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.12.0->tensorflowjs) (1.15.0)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.12.0->tensorflowjs) (2.0.0)\n",
            "Requirement already satisfied: enum34>=1.1.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.12.0->tensorflowjs) (1.1.6)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.12.0->tensorflowjs) (3.6.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.12.0->tensorflowjs) (0.2.1.post0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.12.0->tensorflowjs) (0.32.3)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.12.0->tensorflowjs) (0.6.1)\n",
            "Requirement already satisfied: backports.weakref>=1.0rc1 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.12.0->tensorflowjs) (1.0.post1)\n",
            "Requirement already satisfied: tensorboard<1.13.0,>=1.12.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.12.0->tensorflowjs) (1.12.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.12.0->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.12.0->tensorflowjs) (0.7.1)\n",
            "Requirement already satisfied: futures>=2.2.0 in /usr/local/lib/python2.7/dist-packages (from grpcio>=1.8.6->tensorflow==1.12.0->tensorflowjs) (3.2.0)\n",
            "Requirement already satisfied: funcsigs>=1; python_version < \"3.3\" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0->tensorflow==1.12.0->tensorflowjs) (1.0.2)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0->tensorflow==1.12.0->tensorflowjs) (5.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python2.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.12.0->tensorflowjs) (40.6.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python2.7/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0->tensorflowjs) (0.14.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python2.7/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0->tensorflowjs) (3.0.1)\n",
            "\u001b[31mtensorflow 1.12.0 has requirement keras-applications>=1.0.6, but you'll have keras-applications 1.0.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mtensorflow 1.12.0 has requirement keras-preprocessing>=1.0.5, but you'll have keras-preprocessing 1.0.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mcufflinks 0.14.6 has requirement plotly>=3.0.0, but you'll have plotly 1.12.12 which is incompatible.\u001b[0m\n",
            "\u001b[31mastropy 2.0.11 has requirement pytest<3.7,>=2.8, but you'll have pytest 3.10.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mpymc3 3.6 has requirement joblib<0.13.0, but you'll have joblib 0.13.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mfeaturetools 0.4.1 has requirement pandas>=0.23.0, but you'll have pandas 0.22.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, keras-preprocessing, keras-applications, keras, tensorflow-hub, tensorflowjs\n",
            "  Found existing installation: numpy 1.14.6\n",
            "    Uninstalling numpy-1.14.6:\n",
            "      Successfully uninstalled numpy-1.14.6\n",
            "  Found existing installation: Keras-Preprocessing 1.0.5\n",
            "    Uninstalling Keras-Preprocessing-1.0.5:\n",
            "      Successfully uninstalled Keras-Preprocessing-1.0.5\n",
            "  Found existing installation: Keras-Applications 1.0.6\n",
            "    Uninstalling Keras-Applications-1.0.6:\n",
            "      Successfully uninstalled Keras-Applications-1.0.6\n",
            "  Found existing installation: Keras 2.2.4\n",
            "    Uninstalling Keras-2.2.4:\n",
            "      Successfully uninstalled Keras-2.2.4\n",
            "  Found existing installation: tensorflow-hub 0.2.0\n",
            "    Uninstalling tensorflow-hub-0.2.0:\n",
            "      Successfully uninstalled tensorflow-hub-0.2.0\n",
            "Successfully installed keras-2.2.2 keras-applications-1.0.4 keras-preprocessing-1.0.2 numpy-1.15.1 tensorflow-hub-0.1.1 tensorflowjs-0.6.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "d7UckYemk6D-",
        "colab_type": "code",
        "outputId": "e6236708-ceb7-4981-e9a6-af7ad80f3bfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import random\n",
        "\n",
        "# Helper libraries\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.io import wavfile\n",
        "import six\n",
        "\n",
        "import pydash\n",
        "from pydash import map_\n",
        "from pydash import uniq\n",
        "from pydash import sorted_uniq, uniq_by\n",
        "\n",
        "import json\n",
        "\n",
        "\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SOPIUKiG0kCY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Carga de datos de inacap - ingreso 2015"
      ]
    },
    {
      "metadata": {
        "id": "HbMu1ft2-pa7",
        "colab_type": "code",
        "outputId": "9c4998f8-31e5-46e7-cc6c-2f2d70be8be7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "!curl -o inacap_2015.json https://raw.githubusercontent.com/elaval/datasets/master/desercion/inacap_2015.json\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 18.0M  100 18.0M    0     0  40.9M      0 --:--:-- --:--:-- --:--:-- 40.9M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dggnQ9J2k1Yn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('inacap_2015.json') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I5RA9yWIwvCl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Feature extraction"
      ]
    },
    {
      "metadata": {
        "id": "Qtn5geqhw0UF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "features = ['ciudad_sede', 'codigo_unico', 'nem_cod_depe', 'nem_percentil', 'nivel_global', 'nomb_carrera', 'nomb_inst', 'origin', 'tipo_inst_1']\n",
        "\n",
        "collection = {}\n",
        "dict = {}\n",
        "for f in features:\n",
        "  collection[f] = sorted_uniq(map_(data, lambda x: x[f] if f in x else \"N/A\")) \n",
        "  dict[f] = {k: v for v, k in enumerate(collection[f])}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xFQRMU3v0T-L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "indices = {}  \n",
        "tensor = {}\n",
        "\n",
        "for f in features:\n",
        "  indices[f] = map_(data, lambda x: dict[f][x[f] if f in x else \"N/A\"])\n",
        "  tensor[f] = tf.one_hot(indices[f], len(collection[f]))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JuM-ZsBBTVxz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tipoDesercion(item):\n",
        "  \n",
        "  if not item['potencialDesercion'] :\n",
        "    tipo = 0\n",
        "  elif item['potencialDesercion'] and item['fullDropout']:\n",
        "    tipo = 1\n",
        "  elif (item['potencialDesercion'] and item['cambioInstitucion'] ):\n",
        "    tipo = 2\n",
        "  else :\n",
        "    tipo = 3\n",
        "  return tipo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cO8XiPb_gRXI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "indice_desercion = map_(data, tipoDesercion )\n",
        "tensorY = tf.one_hot(indice_desercion, 4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IQIWhntAfULd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Combined features"
      ]
    },
    {
      "metadata": {
        "id": "QPzBtTI_fZde",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "combinedFeatures = [\"ciudad_sede\", \"nomb_carrera\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F8hUE13ofh2r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "combinedTensorList = []\n",
        "combinedDims = 0\n",
        "for f in combinedFeatures:\n",
        "  combinedTensorList.append(tensor[f])\n",
        "  combinedDims = combinedDims + len(collection[f])\n",
        "  \n",
        "combinedTensor = tf.concat(combinedTensorList,1)\n",
        "\n",
        "combinedModel = keras.Sequential([\n",
        "    keras.layers.Dense(combinedDims, input_dim = combinedDims, activation=tf.nn.relu),\n",
        "    keras.layers.Dense(4, activation=tf.nn.softmax)\n",
        "  ])\n",
        "combinedModel.compile(optimizer=tf.train.AdamOptimizer(), \n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ODklaooJgA5B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a39f193f-bf91-4e3c-a996-b4590a09b7bb"
      },
      "cell_type": "code",
      "source": [
        "combinedModel.fit(combinedTensor, indice_desercion, epochs=5, steps_per_epoch= 100)\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "100/100 [==============================] - 18s 181ms/step - loss: 1.0387 - acc: 0.5814\n",
            "Epoch 2/5\n",
            "100/100 [==============================] - 19s 189ms/step - loss: 1.0372 - acc: 0.5817\n",
            "Epoch 3/5\n",
            "100/100 [==============================] - 19s 188ms/step - loss: 1.0362 - acc: 0.5818\n",
            "Epoch 4/5\n",
            "100/100 [==============================] - 19s 189ms/step - loss: 1.0354 - acc: 0.5819\n",
            "Epoch 5/5\n",
            "100/100 [==============================] - 19s 188ms/step - loss: 1.0349 - acc: 0.5819\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa0c02c9a50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "metadata": {
        "id": "vOj9ugKMj6D5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Save combined model"
      ]
    },
    {
      "metadata": {
        "id": "i6QcUEbVj4zK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "3878b767-18fd-455a-e5c6-8690f5c06ab5"
      },
      "cell_type": "code",
      "source": [
        "combinedModelPath = \"\"\n",
        "for i, f  in enumerate(combinedFeatures):\n",
        "  combinedModelPath =  combinedModelPath + (\"_\" if i > 0 else \"\") + f \n",
        "combinedModel.save('out/model_%s.h5' % combinedModelPath)\n",
        "!tensorflowjs_converter --input_format=keras ./out/model_{combinedModelPath}.h5 ./out/model_{combinedModelPath}_tfjs\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bCN7qsBio5Ny",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uYUXoSgLVK-5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Carga de modelos"
      ]
    },
    {
      "metadata": {
        "id": "eLZCNtcBVkhM",
        "colab_type": "code",
        "outputId": "7453660c-c512-48a1-f2ab-b821d430dfe7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir out\n",
        "model = {}\n",
        "for f in features:\n",
        "  !curl -o out/model__{f}.h5 https://raw.githubusercontent.com/elaval/datasets/master/desercion_inacap/model__{f}.h5\n",
        "  \n",
        "  modelPath = \"out/model__%s.h5\" % f\n",
        "  model[f] = tf.keras.models.load_model(\n",
        "    modelPath,\n",
        "    custom_objects=None,\n",
        "    compile=True\n",
        "  )\n",
        "  model[f].compile(optimizer=tf.train.AdamOptimizer(), \n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘out’: File exists\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 14416  100 14416    0     0   281k      0 --:--:-- --:--:-- --:--:--  281k\n",
            "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 4514k  100 4514k    0     0  20.1M      0 --:--:-- --:--:-- --:--:-- 20.1M\n",
            "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 14416  100 14416    0     0    98k      0 --:--:-- --:--:-- --:--:--   99k\n",
            "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 14416  100 14416    0     0    99k      0 --:--:-- --:--:-- --:--:--   99k\n",
            "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 14416  100 14416    0     0  96751      0 --:--:-- --:--:-- --:--:-- 96751\n",
            "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 57128  100 57128    0     0   379k      0 --:--:-- --:--:-- --:--:--  382k\n",
            "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 14432  100 14432    0     0  97513      0 --:--:-- --:--:-- --:--:-- 97513\n",
            "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 17632  100 17632    0     0   120k      0 --:--:-- --:--:-- --:--:--  120k\n",
            "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 14432  100 14432    0     0    99k      0 --:--:-- --:--:-- --:--:--   99k\n",
            "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JFht-sse0wmA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Definición de modelos"
      ]
    },
    {
      "metadata": {
        "id": "uwRfyOvNYBj_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create models from scratch\n",
        "When models have not been loaded"
      ]
    },
    {
      "metadata": {
        "id": "NoPEZRf3X-8f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = {}\n",
        "for f in features:\n",
        "  dims = len(collection[f])\n",
        "  model[f] = keras.Sequential([\n",
        "    keras.layers.Dense(dims, input_dim = dims, activation=tf.nn.relu),\n",
        "    keras.layers.Dense(4, activation=tf.nn.softmax)\n",
        "  ])\n",
        "  model[f].compile(optimizer=tf.train.AdamOptimizer(), \n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aoUR0us1Y3o3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train models"
      ]
    },
    {
      "metadata": {
        "id": "KyD69Mm9ZEZG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_epochs = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t8oYN-1RY-dR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "11c75ca4-6021-4c31-b34f-189492c24520"
      },
      "cell_type": "code",
      "source": [
        "for f in features:\n",
        "  model[f].fit(tensor[f], indice_desercion, epochs=num_epochs, steps_per_epoch= 100)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "100/100 [==============================] - 3s 29ms/step - loss: 1.1594 - acc: 0.5466\n",
            "Epoch 1/1\n",
            "100/100 [==============================] - 404s 4s/step - loss: 0.9905 - acc: 0.5960\n",
            "Epoch 1/1\n",
            "100/100 [==============================] - 3s 34ms/step - loss: 1.1612 - acc: 0.5466\n",
            "Epoch 1/1\n",
            "100/100 [==============================] - 4s 41ms/step - loss: 1.1485 - acc: 0.5466\n",
            "Epoch 1/1\n",
            "100/100 [==============================] - 3s 34ms/step - loss: 1.1653 - acc: 0.5486\n",
            "Epoch 1/1\n",
            "100/100 [==============================] - 18s 177ms/step - loss: 1.0674 - acc: 0.5747\n",
            "Epoch 1/1\n",
            "100/100 [==============================] - 2s 22ms/step - loss: 1.1456 - acc: 0.5466\n",
            "Epoch 1/1\n",
            "100/100 [==============================] - 4s 37ms/step - loss: 1.1460 - acc: 0.5467\n",
            "Epoch 1/1\n",
            "100/100 [==============================] - 2s 23ms/step - loss: 1.1462 - acc: 0.5466\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Yf9s47ekY-Et",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "ji6WSe56042c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Almacenamiento de modelos y datos"
      ]
    },
    {
      "metadata": {
        "id": "g8m203zYZtIR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "4315f553-75d9-454d-cb74-f1c69e0bb2ea"
      },
      "cell_type": "code",
      "source": [
        "for f in features:\n",
        "  print(\"Feature: %s\" % f)\n",
        "  # Save collections\n",
        "  with open('out/%s.txt' % f, 'w') as file:\n",
        "    file.write(\"%s\\n\" % f)\n",
        "    for item in collection[f]:\n",
        "      if isinstance(item, six.string_types):\n",
        "        file.write(\"%s\\n\" % item.encode('utf-8'))\n",
        "      else:\n",
        "        file.write(\"%d\\n\" % item)\n",
        "  model[f].save('out/model_%s.h5' % f)\n",
        "  !tensorflowjs_converter --input_format=keras ./out/model_{f}.h5 ./out/model_{f}_tfjs\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature: ciudad_sede\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "Using TensorFlow backend.\n",
            "Feature: codigo_unico\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "Using TensorFlow backend.\n",
            "Feature: nem_cod_depe\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "Using TensorFlow backend.\n",
            "Feature: nem_percentil\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "Using TensorFlow backend.\n",
            "Feature: nivel_global\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "Using TensorFlow backend.\n",
            "Feature: nomb_carrera\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "Using TensorFlow backend.\n",
            "Feature: nomb_inst\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "Using TensorFlow backend.\n",
            "Feature: origin\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "Using TensorFlow backend.\n",
            "Feature: tipo_inst_1\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tQRxpc_cawy9",
        "colab_type": "code",
        "outputId": "61f7377b-dfc9-4dd2-e414-66cae3c2ce9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Kq8ft4_Bbf9d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp -r out \"drive/My Drive/_tensorflow\"\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nKZCuAMNejMt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}